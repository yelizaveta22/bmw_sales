{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d88980",
   "metadata": {},
   "source": [
    "## –í–≤–µ–¥–µ–Ω–∏–µ\n",
    "\n",
    "–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∞–Ω–∞–ª–∏–∑–∞ –º—ã –∑–∞–≥—Ä—É–∑–∏–º **–¥–∞–Ω–Ω—ã–µ –æ –ª–µ–¥–Ω–∏–∫–∞—Ö –∏–∑ –±–∞–∑—ã WGMS** –∏ –≤—ã–ø–æ–ª–Ω–∏–º –∏—Ö –ø–µ—Ä–≤–∏—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.\n",
    "–ù–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, **–≤ –∫–∞–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∞—Ö –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –ª–µ–¥–Ω–∏–∫–æ–≤, –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–∞—Å–æ—Ç—É –ª–µ–¥–Ω–∏–∫–∞**, –∞ —Ç–∞–∫–∂–µ **—Å–∫–æ–ª—å–∫–æ —Å–∞–Ω—Ç–∏–º–µ—Ç—Ä–æ–≤ –≤ –≥–æ–¥ —Ç–µ—Ä—è—é—Ç –ª–µ–¥–Ω–∏–∫–∏ –≤ —Å—Ç—Ä–∞–Ω–µ, –∫—É–¥–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç—Å—è –±–µ–ª–∫–∞**.\n",
    "\n",
    "–í—Å–µ —ç—Ç–∏ —Ä–∞—Å—á–µ—Ç—ã –ø–æ–º–æ–≥—É—Ç –Ω–∞—à–µ–π –±–µ–ª–∫–µ üêøÔ∏è –ø–æ–Ω—è—Ç—å, –Ω–∞ –∫–∞–∫–æ–º –ª–µ–¥–Ω–∏–∫–µ –ª–µ–¥ üßä –ø—Ä–æ—á–Ω–µ–µ, –∞ –∑–Ω–∞—á–∏—Ç - –∫—É–¥–∞ –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ —Å–ø—Ä—è—Ç–∞—Ç—å –∂–µ–ª—É–¥—å, —á—Ç–æ–±—ã –Ω–µ —Å–ª—É—á–∏–ª—Å—è ‚ò†Ô∏è*–∞–ø–æ–∫–∞–ª–∏–ø—Å–∏—Å*‚ò†Ô∏è\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81870e27-a962-4cee-a993-c9aac244a1f8",
   "metadata": {},
   "source": [
    "–û—Ç–∫—Ä–æ–µ–º –Ω–∞—à–∏ –¥–∞—Ç–∞—Å–µ—Ç–∏–∫–∏ üßäüêøÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fda48f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞ change_band.csv:\n",
      "country,glacier_name,glacier_id,change_id,lower_elevation,upper_elevation,area,elevation_change,elevation_change_unc,volume_change,volume_change_unc,remarks\n",
      "AR,MARTIAL,917,745,780,800,,,,,,\n",
      "AR,MARTIAL,917,745,800,900,,,,,,\n",
      "AR,MARTIAL,917,745,900,1000,,,,,,\n",
      "AR,MARTIAL,917,745,1000,1100,,,,,,\n",
      "\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ change_band.csv: 4009\n"
     ]
    }
   ],
   "source": [
    "with open('change_band.csv', 'r', encoding='utf-8') as file:\n",
    "    change_data = file.readlines()\n",
    "\n",
    "print('–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞ change_band.csv:')\n",
    "for line in change_data[:5]:\n",
    "    print(line.strip())\n",
    "\n",
    "print('\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ change_band.csv:', len(change_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76696e6",
   "metadata": {},
   "source": [
    "## –¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º —Å–∫–æ–ª—å–∫–æ –ª–µ–¥–Ω–∏–∫–æ–≤ –≤ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–µ –µ—Å—Ç—å ‚õ∞Ô∏è\n",
    "\n",
    "–ù–∞—á–Ω–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª —Å—Ä–∞–∑—É, —Ç–∞–∫ –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å—Ç—ã–µ, –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29cf785f-68a6-4ef8-a53a-7ac2857ee464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–µ–¥–Ω–∏–∫–æ–≤ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º:\n",
      "AR: 2\n",
      "AT: 13\n",
      "BO: 2\n",
      "CA: 10\n",
      "CH: 6\n",
      "CO: 2\n",
      "DE: 5\n",
      "ES: 1\n",
      "IN: 2\n",
      "IS: 1\n",
      "IT: 4\n",
      "KE: 1\n",
      "KG: 11\n",
      "KZ: 3\n",
      "NP: 2\n",
      "PK: 7\n",
      "RU: 1\n",
      "SE: 1\n",
      "SJ: 1\n",
      "TJ: 1\n",
      "US: 4\n"
     ]
    }
   ],
   "source": [
    "filename = 'change_band.csv'\n",
    "\n",
    "countries_dict = {}\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        parts = line.split(',')\n",
    "\n",
    "        if len(parts) < 3:  # Check that the string has at least 3 parts (country, name, ID)\n",
    "            continue\n",
    "\n",
    "        # Take the country (first part) and the glacier ID (third part)\n",
    "        country = parts[0]\n",
    "        glacier_id_str = parts[2]\n",
    "\n",
    "        # Check that the ID string and country are not empty\n",
    "        # Check that the ID is a number\n",
    "        # And check if the string consists only of digits\n",
    "        if glacier_id_str.isdigit() and country:\n",
    "            if country not in countries_dict: # If the country is not yet in the dictionary,create an empty set\n",
    "                countries_dict[country] = set()\n",
    "\n",
    "            countries_dict[country].add(glacier_id_str)  # Adding the glacier ID to the set for this country\n",
    "\n",
    "print('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–µ–¥–Ω–∏–∫–æ–≤ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º:')\n",
    "for country in sorted(countries_dict.keys()):\n",
    "    count = len(countries_dict[country])\n",
    "    print(f'{country}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491286e",
   "metadata": {},
   "source": [
    "## –í—ã–≤–µ–¥–µ–º —Å—Ç—Ä–∞–Ω—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ª–µ–¥–Ω–∏–∫–æ–≤ üßä\n",
    "–ß–µ–∫–∞–µ–º —Å–∞–º—ã–º –ø—Ä–æ—Å—Ç—ã–º —Å–ø–æ—Å–æ–±–æ–º: —á–µ—Ä–µ–∑ —Ü–∏–∫–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59b1eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°—Ç—Ä–∞–Ω–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ª–µ–¥–Ω–∏–∫–æ–≤: AT (13)\n"
     ]
    }
   ],
   "source": [
    "max_country = ''\n",
    "max_count = 0\n",
    "    # Check all the countries and their number of dictionary\n",
    "for country in countries_dict:\n",
    "    count = len(countries_dict[country])\n",
    " \n",
    "    if count > max_count:\n",
    "        max_count = count\n",
    "        max_country = country\n",
    "\n",
    "print(f'–°—Ç—Ä–∞–Ω–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ª–µ–¥–Ω–∏–∫–æ–≤: {max_country} ({max_count})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26ec5c-73f1-4c4b-bacb-128adea75570",
   "metadata": {},
   "source": [
    "## –¢–µ–ø–µ—Ä—å —É–∑–Ω–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤—ã—Å–æ—Ç—É, —á—Ç–æ–±—ã —É –±–µ–ª–∫–∏ –±—ã–ª –¥–æ–ª–≥–∏–π –∏ –∫—Ä—É—Ç–æ–π –ø–æ–¥—ä–µ–º üßóüèø‚Äç‚ôÄÔ∏è\n",
    "–ë–µ–ª–∫–∞-–∞–ª—å–ø–∏–Ω–∏—Å—Ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4afe2b0-ba3d-4175-98f2-45d5d96a0381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞ –ª–µ–¥–Ω–∏–∫–∞: 6500.0\n",
      "–°—Ç—Ä–∞–Ω–∞: IN\n",
      "–ù–∞–∑–≤–∞–Ω–∏–µ –ª–µ–¥–Ω–∏–∫–∞: BARA SHIGRI\n"
     ]
    }
   ],
   "source": [
    "max_height = 0\n",
    "max_country = ''\n",
    "max_glacier = ''\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    header = file.readline() # Read first line and another lines one by one\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty\n",
    "\n",
    "        parts = line.split(',')\n",
    "\n",
    "        # Check that the string contains the required number of elements\n",
    "        if len(parts) < 6:\n",
    "            continue\n",
    "\n",
    "        country = parts[0]\n",
    "        glacier_name = parts[1]\n",
    "        upper_elevation = parts[5]  # –ïake the sixth element [5 index], since the data on the maximum height is in the 6th column\n",
    "\n",
    "        # If there is a height\n",
    "        if upper_elevation != '':\n",
    "            height = float(upper_elevation)\n",
    "\n",
    "            # If found heigher glacier\n",
    "            if height > max_height:\n",
    "                max_height = height\n",
    "                max_country = country\n",
    "                max_glacier = glacier_name\n",
    "\n",
    "print('–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞ –ª–µ–¥–Ω–∏–∫–∞:', max_height)\n",
    "print('–°—Ç—Ä–∞–Ω–∞:', max_country)\n",
    "print('–ù–∞–∑–≤–∞–Ω–∏–µ –ª–µ–¥–Ω–∏–∫–∞:', max_glacier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67948a07",
   "metadata": {},
   "source": [
    "## –û–ö–ê–ö. –ë–µ–ª–æ—á–∫–∞ –ª–µ—Ç–∏—Ç –≤ –ò–Ω–¥–∏—é... –ù–∞–≤–µ—Ä–Ω–æ–µ. üçõ\n",
    "\n",
    "–ú—ã –Ω–∞—à–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤—ã—Å–æ—Ç—É –ª–µ–¥–Ω–∏–∫–∞, –Ω–æ —Ç–µ–ø–µ—Ä—å –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∞ –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ –±—ã—Å—Ç—Ä–æ —Ç–µ—Ä—è—é—Ç —Å–≤–æ—é –º–∞—Å—Å—É –ª–µ–¥–Ω–∏–∫–∏ –≤ –ò–Ω–¥–∏–∏. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–Ω–¥–µ–∫—Å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—ã—Å–æ—Ç—ã –ª–µ–¥–Ω–∏–∫–æ–≤ (—Å–º/–≥–æ–¥)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "933ac9e7-7dac-4107-aab1-c9626b5105ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–Ω–∞—á–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—ã—Å–æ—Ç –¥–ª—è –ª–µ–¥–Ω–∏–∫–æ–≤ –ò–Ω–¥–∏–∏:\n",
      "2.882\n",
      "1.455\n",
      "0.928\n",
      "0.633\n",
      "0.617\n",
      "0.385\n",
      "-0.246\n",
      "-0.608\n",
      "-0.95\n",
      "-1.224\n",
      "-1.622\n",
      "-1.84\n",
      "-1.919\n",
      "-2.348\n",
      "-2.642\n",
      "-3.024\n",
      "-3.065\n",
      "-3.114\n",
      "-3.544\n",
      "-3.631\n",
      "-3.718\n",
      "-3.812\n",
      "-3.964\n",
      "-4.014\n",
      "-4.022\n",
      "-4.102\n",
      "-4.352\n",
      "-4.555\n",
      "-5.5\n",
      "-5.526\n",
      "-6.641\n",
      "-6.7\n",
      "-7.629\n",
      "-8.247\n",
      "-8.513\n",
      "-8.979\n",
      "-9.139\n",
      "-9.141\n",
      "-9.767\n",
      "-9.799\n",
      "-10.008\n",
      "-10.633\n",
      "-10.929\n",
      "-11.148\n",
      "-11.905\n"
     ]
    }
   ],
   "source": [
    "india_elev_changes = []\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    header = file.readline().strip().split(',')\n",
    "\n",
    "    country_index = header.index('country')\n",
    "    elev_index = header.index('elevation_change')\n",
    "\n",
    "    for line in file:\n",
    "        parts = line.strip().split(',')\n",
    "\n",
    "        if parts[country_index] == 'IN':\n",
    "            elev_value = parts[elev_index]\n",
    "\n",
    "            # Check if empty or not\n",
    "            if elev_value != '':\n",
    "                india_elev_changes.append(float(elev_value))\n",
    "\n",
    "# sort from largest to smallest\n",
    "india_elev_changes.sort(reverse=True)\n",
    "\n",
    "print('–ó–Ω–∞—á–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—ã—Å–æ—Ç –¥–ª—è –ª–µ–¥–Ω–∏–∫–æ–≤ –ò–Ω–¥–∏–∏:')\n",
    "for value in india_elev_changes:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279dfceb-460e-4a67-87b9-c1bfdb95072f",
   "metadata": {},
   "source": [
    "–ë–µ–ª–∫–∞ –ø–æ–µ–¥–µ—Ç –≤ –ò–Ω–¥–∏—é, –ø–æ—Ç–æ–º—É —á—Ç–æ –ª–µ–¥–Ω–∏–∫–∏ —Ç–∞–º —Å–º–æ–≥—É—Ç —É–±–µ—Ä–µ—á—å –µ–µ –∂–µ–ª—É–¥—å, –≤–µ–¥—å –æ–Ω–∏ —Ä–∞—Å—Å—Ç–∞—é—Ç –µ—â–µ –Ω–µ —Å–∫–æ—Ä–æ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c53a2-dcce-42de-98c3-72e52bb60b4f",
   "metadata": {},
   "source": [
    "## –ù–æ –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –º–æ–∂–µ—Ç –ª–∏ –æ–Ω–∞ –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤–∞–≥–æ–Ω –∏ –º–∞–ª–µ–Ω—å–∫—É—é —Ç–µ–ª–µ–∂–∫—É –∂–µ–ª—É–¥–µ–π, –≤–µ–¥—å –±–µ–ª–∫–∞ –æ—á–µ–Ω—å –ª—é–±–∏—Ç –∑–∞–ø–∞—Å–∞—Ç—å—Å—è –Ω–∞ –∑–∏–º—É üõí (–Ω–∞ —Ü–µ–ª—ã–π –õ–µ–¥–Ω–∏–∫–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥)\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞–µ–º –≤—ã—Å–æ—Ç—É –ª–µ–¥–Ω–∏–∫–∞, –∞ –∑–∞—Ç–µ–º –æ–±—â—É—é –ø–ª–æ—â–∞–¥—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8c623e17-936e-4fbb-b57b-9eed4c773a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—â–∞—è –≤—ã—Å–æ—Ç–∞ –ª–µ–¥–Ω–∏–∫–∞ –ë–∞—Ä–∞ –®–∏–≥—Ä–∏: 2600.0\n"
     ]
    }
   ],
   "source": [
    "uppers = []\n",
    "lowers = []\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    header = file.readline().strip().split(',')\n",
    "\n",
    "    name_index = header.index('glacier_name')\n",
    "    lower_index = header.index('lower_elevation')\n",
    "    upper_index = header.index('upper_elevation')\n",
    "\n",
    "    for line in file:\n",
    "        parts = line.strip().split(',')\n",
    "\n",
    "        # looking for lines with a glacier bara shigri\n",
    "        if 'bara shigri' in parts[name_index].lower():\n",
    "            lower = parts[lower_index]\n",
    "            upper = parts[upper_index]\n",
    "\n",
    "            # Check empty or not\n",
    "            if lower != '' and upper != '':\n",
    "                lowers.append(float(lower))\n",
    "                uppers.append(float(upper))\n",
    "\n",
    "# –°alculate the total height\n",
    "if lowers and uppers:\n",
    "    total_height = max(uppers) - min(lowers)\n",
    "    print('–û–±—â–∞—è –≤—ã—Å–æ—Ç–∞ –ª–µ–¥–Ω–∏–∫–∞ –ë–∞—Ä–∞ –®–∏–≥—Ä–∏:', total_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b8d8fe61-633f-4e13-8c40-0735b5e392be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –ª–µ–¥–Ω–∏–∫–∞ –ë–∞—Ä–∞ –®–∏–≥—Ä–∏: 131099801.0\n"
     ]
    }
   ],
   "source": [
    "total_area = 0\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    header = file.readline().strip().split(',')\n",
    "\n",
    "    # Finding the indexes of the required columns\n",
    "    name_index = header.index('glacier_name')\n",
    "    area_index = header.index('area')\n",
    "\n",
    "    # Read another lines\n",
    "    for line in file:\n",
    "        parts = line.strip().split(',')\n",
    "\n",
    "        # check that lines have bara shigri in names\n",
    "        if 'bara shigri' in parts[name_index].lower():\n",
    "            area_str = parts[area_index]\n",
    "\n",
    "            # if is not empty, plus to another\n",
    "            if area_str != '':\n",
    "                total_area += float(area_str)\n",
    "                \n",
    "print('–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –ª–µ–¥–Ω–∏–∫–∞ –ë–∞—Ä–∞ –®–∏–≥—Ä–∏:', total_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5023dec-88a8-4ff7-9da7-b631a2369c28",
   "metadata": {},
   "source": [
    "## –í—Å–µ, –±–µ–ª–∫–∞ –ø–æ–∫—É–ø–∞–µ—Ç –±–∏–ª–µ—Ç—ã –Ω–∞ ‚úàÔ∏è—Å–µ–π–ª—Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6329f-d704-47e7-9af9-754ee5eee54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
